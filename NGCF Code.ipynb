{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-16T13:39:22.354128Z",
     "iopub.status.busy": "2024-09-16T13:39:22.353479Z",
     "iopub.status.idle": "2024-09-16T13:39:22.369111Z",
     "shell.execute_reply": "2024-09-16T13:39:22.367010Z",
     "shell.execute_reply.started": "2024-09-16T13:39:22.354079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import networkx as nx    \n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset \n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.multiprocessing as mp\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-16T12:31:45.896862Z",
     "iopub.status.busy": "2024-09-16T12:31:45.896369Z",
     "iopub.status.idle": "2024-09-16T12:31:45.909975Z",
     "shell.execute_reply": "2024-09-16T12:31:45.908779Z",
     "shell.execute_reply.started": "2024-09-16T12:31:45.896819Z"
    }
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Description**\n",
    "\n",
    "This project uses three datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `train_data.csv`: \n",
    "This dataset contains two years (2022 & 2023) of historical transactions for 100,000 Carrefour customers. It has 10 columns:\n",
    "\n",
    "* ***date***: Date of the transaction\n",
    "* ***transaction_id***: ID of the transaction\n",
    "* ***customer_id***: Customer ID\n",
    "* ***product_id***: Product purchased\n",
    "* ***has_loyality_card***: Flag indicating whether the customer has a loyalty card\n",
    "* ***store_id***: Store where the purchase was made\n",
    "* ***is_promo***: Flag indicating whether there was a discount on the product\n",
    "* ***quantity***: Quantity purchased of the product\n",
    "* ***format***: Ecommerce activity format (clcv, lex, or DRIVE)\n",
    "  - clcv : courses livrées chez vous\n",
    "  - lex : livraison express\n",
    "  - DRIVE.\n",
    "* ***orderChannelCode***: Indicates whether the online activity was made through the website or mobile app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `products_data.csv`: \n",
    "This dataset contains detailed information about the products. The following columns are relevant to this project:\n",
    "\n",
    "* ***product_id*** : Product name\n",
    "* ***product_description*** : Product description\n",
    "* ***department_key***: Department key\n",
    "* ***class_key***: Class key\n",
    "* ***subclass_key***: Subclass key\n",
    "* ***sector***: sector name\n",
    "* ***brand_key***: Brand name\n",
    "* ***shelf_level1***: Top-level shelf category\n",
    "* ***shelf_level2***: Second-level shelf category\n",
    "* ***shelf_level3***: Third-level shelf category\n",
    "* ***shelf_level4***: Fourth-level shelf category\n",
    "* ***sector***: Sector\n",
    "* ***bio***: Flag indicating whether the product is organic\n",
    "* ***sugar_free***: Flag indicating whether the product is sugar-free\n",
    "* ***aspartame_free***: Flag indicating whether the product is aspartame-free\n",
    "* ***gluten_free***: Flag indicating whether the product is gluten-free\n",
    "* ***halal***: Flag indicating whether the product is halal\n",
    "* ***casher***: Flag indicating whether the product is kosher\n",
    "* ***eco_friendly***: Flag indicating whether the product is eco-friendly\n",
    "* ***local_french***: Flag indicating whether the product is locally produced in France\n",
    "* ***artificial_coloring_free***: Flag indicating whether the product is free of artificial coloring\n",
    "* ***taste_enhancer_free***: Flag indicating whether the product is free of taste enhancers\n",
    "* ***naturality***: Naturality score\n",
    "* ***antibiotic_free***: Flag indicating whether the product is antibiotic-free\n",
    "* ***reduced_sugar***: Flag indicating whether the product has reduced sugar content\n",
    "* ***vegetarian***: Flag indicating whether the product is vegetarian\n",
    "* ***pesticide_free***: Flag indicating whether the product is pesticide-free\n",
    "* ***grain_free***: Flag indicating whether the product is grain-free\n",
    "* ***no_added_sugar***: Flag indicating whether the product has no added sugar\n",
    "* ***salt_reduced***: Flag indicating whether the product has reduced salt content\n",
    "* ***nitrite_free***: Flag indicating whether the product is nitrite-free\n",
    "* ***fed_without_ogm***: Flag indicating whether the animals were fed without GMOs\n",
    "* ***no_added_salt***: Flag indicating whether the product has no added salt\n",
    "* ***no_artificial_flavours***: Flag indicating whether the product has no artificial flavors\n",
    "* ***porc***: Flag indicating whether the product contains pork\n",
    "* ***vegan***: Flag indicating whether the product is vegan\n",
    "* ***frozen***: Flag indicating whether the product is frozen\n",
    "* ***fat_free***: Flag indicating whether the product is fat-free\n",
    "* ***reduced_fats***: Flag indicating whether the product has reduced fat content\n",
    "* ***fresh***: Flag indicating whether the product is fresh\n",
    "* ***alcool***: Flag indicating whether the product contains alcohol\n",
    "* ***lactose_free***: Flag indicating whether the product is lactose-free\n",
    "* ***phenylalanine_free***: Flag indicating whether the product is phenylalanine-free\n",
    "* ***palm_oil_free***: Flag indicating whether the product is palm oil-free\n",
    "* ***ecoscore***: Ecoscore\n",
    "* ***produits_du_monde***: Flag indicating whether the product is an international product\n",
    "* ***regional_product***: Flag indicating whether the product is a regional product\n",
    "* ***national_brand***: Flag indicating whether the product is a national brand\n",
    "* ***first_price_brand***: Flag indicating whether the product is a first-price brand\n",
    "* ***carrefour_brand***: Flag indicating whether the product is a Carrefour brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `test_data.csv`: \n",
    "This dataset contains the actual purchases of the first 80,000 customers in 2024. It has three columns:\n",
    "\n",
    "* ***transaction_id***: ID of the transaction\n",
    "* ***customer_id***: Customer ID\n",
    "* ***product_id***: the id of the purchased product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load data**\n",
    "\n",
    "* Load *train_data.csv*, *products_data.csv* and *test_data.csv* using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T12:31:45.912350Z",
     "iopub.status.busy": "2024-09-16T12:31:45.911439Z",
     "iopub.status.idle": "2024-09-16T12:36:25.806963Z",
     "shell.execute_reply": "2024-09-16T12:36:25.805257Z",
     "shell.execute_reply.started": "2024-09-16T12:31:45.912303Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:41<00:00, 16.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87037462, 10)\n",
      "         date       transaction_id     customer_id     product_id  \\\n",
      "0  2023-11-15  Transaction_1730125    Household_39   Product_5362   \n",
      "1  2022-07-20  Transaction_1560535    Household_39  Product_67174   \n",
      "2  2022-07-20  Transaction_1560535    Household_39  Product_82254   \n",
      "3  2023-11-15  Transaction_1730125    Household_39   Product_3895   \n",
      "4  2022-07-20  Transaction_1560535    Household_39  Product_34014   \n",
      "5  2023-07-12  Transaction_1479608   Household_167   Product_8327   \n",
      "6  2023-07-18   Transaction_993002   Household_167   Product_3846   \n",
      "7  2023-02-16  Transaction_1318448   Household_416  Product_21347   \n",
      "8  2022-06-13  Transaction_1372043  Household_1264  Product_39217   \n",
      "9  2022-06-13  Transaction_1372043  Household_1264  Product_36923   \n",
      "\n",
      "   has_loyality_card store_id  is_promo  quantity format order_channel  \n",
      "0                  0  Store_2         0       1.0  DRIVE    MOBILE_APP  \n",
      "1                  0  Store_2         0       2.0  DRIVE       WEBSITE  \n",
      "2                  0  Store_2         0       2.0  DRIVE       WEBSITE  \n",
      "3                  0  Store_2         0       1.0  DRIVE    MOBILE_APP  \n",
      "4                  0  Store_2         0       1.0  DRIVE       WEBSITE  \n",
      "5                  0  Store_2         0       1.0  DRIVE    MOBILE_APP  \n",
      "6                  0  Store_2         0       2.0  DRIVE    MOBILE_APP  \n",
      "7                  0  Store_2         0       2.0  DRIVE       WEBSITE  \n",
      "8                  0  Store_2         0       1.0  DRIVE    MOBILE_APP  \n",
      "9                  0  Store_2         0       1.0  DRIVE    MOBILE_APP  \n"
     ]
    }
   ],
   "source": [
    "train_dataframes = []\n",
    "for i in tqdm(range(1, 11)):\n",
    "    train_dataframes.append(pd.read_csv(f'data-train/train_data_part_{i}.csv'))\n",
    "train_data = pd.concat(train_dataframes, ignore_index=True)\n",
    "\n",
    "# free up memory by deleting the dataframes we no longer need\n",
    "del train_dataframes\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T12:36:25.812259Z",
     "iopub.status.busy": "2024-09-16T12:36:25.811804Z",
     "iopub.status.idle": "2024-09-16T12:36:26.569662Z",
     "shell.execute_reply": "2024-09-16T12:36:26.568022Z",
     "shell.execute_reply.started": "2024-09-16T12:36:25.812213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82966, 49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleca\\AppData\\Local\\Temp\\ipykernel_21472\\995799025.py:2: DtypeWarning: Columns (43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  products_data = pd.read_csv('data-train/products_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# This code reads the data from a CSV file named \"products_data.csv\"\n",
    "products_data = pd.read_csv('data-train/products_data.csv')\n",
    "print(products_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T12:36:26.571373Z",
     "iopub.status.busy": "2024-09-16T12:36:26.571006Z",
     "iopub.status.idle": "2024-09-16T12:36:28.060125Z",
     "shell.execute_reply": "2024-09-16T12:36:28.058834Z",
     "shell.execute_reply.started": "2024-09-16T12:36:26.571334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1220706, 3)\n",
      "       transaction_id      customer_id     product_id\n",
      "0  Transaction_2024_1  Household_16874   Product_9790\n",
      "1  Transaction_2024_1  Household_16874  Product_68295\n",
      "2  Transaction_2024_1  Household_16874  Product_19494\n",
      "3  Transaction_2024_1  Household_16874  Product_11109\n",
      "4  Transaction_2024_4   Household_9247  Product_57151\n",
      "5  Transaction_2024_4   Household_9247    Product_379\n",
      "6  Transaction_2024_4   Household_9247  Product_46331\n",
      "7  Transaction_2024_4   Household_9247  Product_49682\n",
      "8  Transaction_2024_5  Household_76806  Product_72217\n",
      "9  Transaction_2024_5  Household_76806   Product_4897\n"
     ]
    }
   ],
   "source": [
    "# This code reads the data from a CSV file named \"test_data.csv\"\n",
    "test_data = pd.read_csv('data-train/test_data.csv')\n",
    "test_data = pd.DataFrame(test_data)\n",
    "\n",
    "print(test_data.shape)\n",
    "print(test_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training set with relevant product information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33485786, 3)\n",
      "     customer_id     product_id  quantity\n",
      "347  Household_1  Product_57942        21\n",
      "421  Household_1  Product_67459        20\n",
      "116  Household_1  Product_24334        18\n",
      "504  Household_1   Product_7783        15\n",
      "51   Household_1  Product_16409        13\n",
      "390  Household_1  Product_64067        12\n",
      "6    Household_1   Product_1128        11\n",
      "541  Household_1    Product_833        10\n",
      "440  Household_1   Product_7006         9\n",
      "97   Household_1  Product_21613         7\n"
     ]
    }
   ],
   "source": [
    "# Aggregate customer purchase data\n",
    "customer_data = train_data.groupby(['customer_id', 'product_id']).agg({\n",
    "    'quantity': 'sum'  # Total quantity purchased per product per customer\n",
    "}).reset_index()\n",
    "\n",
    "customer_data['quantity'] = customer_data['quantity'].astype(int)\n",
    "customer_data = customer_data.sort_values(by=['customer_id', 'quantity'], ascending=[True, False])\n",
    "\n",
    "print(customer_data.shape)\n",
    "print(customer_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T12:36:32.562661Z",
     "iopub.status.busy": "2024-09-16T12:36:32.562209Z",
     "iopub.status.idle": "2024-09-16T12:37:35.749409Z",
     "shell.execute_reply": "2024-09-16T12:37:35.748024Z",
     "shell.execute_reply.started": "2024-09-16T12:36:32.562619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id  product_id  quantity   brand_key             shelf_level1  \\\n",
      "0            1       57942        21  CRISTALINE                 Boissons   \n",
      "1            1       67459        20  FLEURY MIC  Charcuterie et Traiteur   \n",
      "2            1       24334        18       SIMPL   Entretien et Nettoyage   \n",
      "3            1        7783        15   CRF CLASS                 Boissons   \n",
      "4            1       16409        13  ZZZZZZZZZZ        Fruits et Légumes   \n",
      "\n",
      "                                shelf_level2  \\\n",
      "0                                       Eaux   \n",
      "1                                Charcuterie   \n",
      "2  Essuie-tout, Papier toilette et Mouchoirs   \n",
      "3                   Jus de fruits et légumes   \n",
      "4                                     Fruits   \n",
      "\n",
      "                        shelf_level3  bio  sugar_free  gluten_free  halal  \\\n",
      "0                        Eaux plates    0           0            0      0   \n",
      "1            Jambons blancs et Rôtis    0           0            0      0   \n",
      "2                          Mouchoirs    0           0            0      0   \n",
      "3  Jus multifruits et multivitaminés    0           0            0      0   \n",
      "4                   Fruits exotiques    0           0            0      0   \n",
      "\n",
      "   reduced_sugar  vegetarian  vegan  pesticide_free  no_added_sugar  \\\n",
      "0              0           0      0               0               0   \n",
      "1              0           0      0               0               0   \n",
      "2              0           0      0               0               0   \n",
      "3              0           0      0               0               0   \n",
      "4              0           0      0               0               0   \n",
      "\n",
      "   salt_reduced  no_added_salt  no_artificial_flavours  porc  frozen  \\\n",
      "0             0              0                       0     0       0   \n",
      "1             0              0                       0     1       0   \n",
      "2             0              0                       0     0       0   \n",
      "3             0              0                       0     0       0   \n",
      "4             0              0                       0     0       0   \n",
      "\n",
      "   fat_free  reduced_fats  fresh  alcool  lactose_free  \n",
      "0         0             0      0       0             0  \n",
      "1         0             0      0       0             0  \n",
      "2         0             0      0       0             0  \n",
      "3         0             0      0       0             0  \n",
      "4         0             0      0       0             0  \n",
      "(33511768, 26)\n"
     ]
    }
   ],
   "source": [
    "features_to_keep = [\n",
    "    'product_id', 'brand_key', 'shelf_level1', 'shelf_level2', 'shelf_level3',\n",
    "    'bio', 'sugar_free', 'gluten_free', 'halal', 'reduced_sugar', 'vegetarian', 'vegan',\n",
    "    'pesticide_free', 'no_added_sugar', 'salt_reduced', 'no_added_salt', 'no_artificial_flavours', \n",
    "    'porc', 'frozen', 'fat_free', 'reduced_fats', 'fresh', 'alcool', 'lactose_free'\n",
    "]\n",
    "\n",
    "# Select only the required columns from the products table for efficiency\n",
    "products_reduced = products_data[features_to_keep]\n",
    "\n",
    "# Merge customer_data with the filtered products table on 'product_id'\n",
    "purchase_data = customer_data.merge(products_reduced, on='product_id', how='inner')\n",
    "\n",
    "# Convert customer_id and product_id to integer IDs (removing non-numeric characters)\n",
    "purchase_data['customer_id'] = purchase_data['customer_id'].str.replace('Household_', '').astype(int)\n",
    "purchase_data['product_id'] = purchase_data['product_id'].str.replace('Product_', '').astype(int)\n",
    "\n",
    "purchase_data = purchase_data.sort_values(by=['customer_id', 'quantity'], ascending=[True, False])\n",
    "\n",
    "# Display the result\n",
    "print(purchase_data.head())\n",
    "\n",
    "# Check the shape to ensure efficient merging\n",
    "print(purchase_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id  product_id  quantity  bio  sugar_free  gluten_free  halal  \\\n",
      "0            1       57942  0.004157    0           0            0      0   \n",
      "1            1       67459  0.003949    0           0            0      0   \n",
      "2            1       24334  0.003534    0           0            0      0   \n",
      "3            1        7783  0.002910    0           0            0      0   \n",
      "4            1       16409  0.002494    0           0            0      0   \n",
      "\n",
      "   reduced_sugar  vegetarian  vegan  pesticide_free  no_added_sugar  \\\n",
      "0              0           0      0               0               0   \n",
      "1              0           0      0               0               0   \n",
      "2              0           0      0               0               0   \n",
      "3              0           0      0               0               0   \n",
      "4              0           0      0               0               0   \n",
      "\n",
      "   salt_reduced  no_added_salt  no_artificial_flavours  porc  frozen  \\\n",
      "0             0              0                       0     0       0   \n",
      "1             0              0                       0     1       0   \n",
      "2             0              0                       0     0       0   \n",
      "3             0              0                       0     0       0   \n",
      "4             0              0                       0     0       0   \n",
      "\n",
      "   fat_free  reduced_fats  fresh  alcool  lactose_free  brand_key_encoded  \\\n",
      "0         0             0      0       0             0           0.025773   \n",
      "1         0             0      0       0             0           0.032647   \n",
      "2         0             0      0       0             0           0.214299   \n",
      "3         0             0      0       0             0           1.000000   \n",
      "4         0             0      0       0             0           0.491694   \n",
      "\n",
      "   shelf_level1_encoded  shelf_level2_encoded  shelf_level3_encoded  \n",
      "0              0.395848              0.180404              0.286613  \n",
      "1              0.494077              0.636907              0.601373  \n",
      "2              0.409608              0.258997              0.261366  \n",
      "3              0.395848              0.189663              0.133840  \n",
      "4              0.686628              0.463111              0.114391  \n"
     ]
    }
   ],
   "source": [
    "# Define the frequency encoding function\n",
    "def frequency_encode(df, column):\n",
    "    freq = df[column].value_counts()  # Calculate frequencies of each category\n",
    "    return df[column].map(freq)  # Map categories to their corresponding frequencies\n",
    "\n",
    "# Apply frequency encoding to the specified categorical columns\n",
    "purchase_data['brand_key_encoded'] = frequency_encode(purchase_data, 'brand_key')\n",
    "purchase_data['shelf_level1_encoded'] = frequency_encode(purchase_data, 'shelf_level1')\n",
    "purchase_data['shelf_level2_encoded'] = frequency_encode(purchase_data, 'shelf_level2')\n",
    "purchase_data['shelf_level3_encoded'] = frequency_encode(purchase_data, 'shelf_level3')\n",
    "\n",
    "# Drop the original categorical columns\n",
    "purchase_data.drop(['brand_key', 'shelf_level1', 'shelf_level2', 'shelf_level3'], axis=1, inplace=True)\n",
    "\n",
    "# List of columns to normalize\n",
    "numerical_columns = ['quantity', 'brand_key_encoded', 'shelf_level1_encoded', \n",
    "                     'shelf_level2_encoded', 'shelf_level3_encoded']\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the specified numerical columns\n",
    "purchase_data[numerical_columns] = scaler.fit_transform(purchase_data[numerical_columns])\n",
    "\n",
    "\n",
    "# Display the updated dataset\n",
    "print(purchase_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#purchase_data.to_csv('purchase_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#purchase_data = pd.read_csv('purchase_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                transaction_id   customer_id     product_id\n",
      "813978  Transaction_2024_17216   Household_1  Product_15693\n",
      "69458   Transaction_2024_17216   Household_1    Product_170\n",
      "813974  Transaction_2024_17216   Household_1  Product_20576\n",
      "813977  Transaction_2024_17216   Household_1  Product_23579\n",
      "813973  Transaction_2024_17216   Household_1  Product_23625\n",
      "69459   Transaction_2024_17216   Household_1  Product_24334\n",
      "813975  Transaction_2024_17216   Household_1  Product_24503\n",
      "407363  Transaction_2024_17216   Household_1  Product_35730\n",
      "813979  Transaction_2024_17216   Household_1  Product_39719\n",
      "69457   Transaction_2024_17216   Household_1  Product_45719\n",
      "813980  Transaction_2024_17216   Household_1  Product_47925\n",
      "813972  Transaction_2024_17216   Household_1  Product_49682\n",
      "407364  Transaction_2024_17216   Household_1  Product_57011\n",
      "407365  Transaction_2024_17216   Household_1  Product_57942\n",
      "69460   Transaction_2024_17216   Household_1  Product_64067\n",
      "813971  Transaction_2024_17216   Household_1  Product_66850\n",
      "813976  Transaction_2024_17216   Household_1  Product_72217\n",
      "407366  Transaction_2024_17216   Household_1  Product_73323\n",
      "814034   Transaction_2024_2003  Household_10  Product_11769\n",
      "407404   Transaction_2024_2003  Household_10  Product_13961\n",
      "814038   Transaction_2024_2003  Household_10  Product_14244\n",
      "407407   Transaction_2024_2003  Household_10  Product_15166\n",
      "814030   Transaction_2024_2003  Household_10  Product_15268\n",
      "814032   Transaction_2024_2003  Household_10    Product_204\n",
      "407411   Transaction_2024_2003  Household_10  Product_20797\n",
      "407406   Transaction_2024_2003  Household_10  Product_25265\n",
      "8299     Transaction_2024_2003  Household_10  Product_29639\n",
      "814040   Transaction_2024_2003  Household_10   Product_3301\n",
      "407410   Transaction_2024_2003  Household_10   Product_3702\n",
      "814028   Transaction_2024_2003  Household_10  Product_41328\n",
      "8300     Transaction_2024_2003  Household_10  Product_43071\n",
      "814041   Transaction_2024_2003  Household_10  Product_44048\n",
      "407408   Transaction_2024_2003  Household_10  Product_45631\n",
      "407405   Transaction_2024_2003  Household_10   Product_4639\n",
      "407409   Transaction_2024_2003  Household_10  Product_51376\n",
      "814031   Transaction_2024_2003  Household_10  Product_55676\n",
      "814029   Transaction_2024_2003  Household_10   Product_5769\n",
      "814033   Transaction_2024_2003  Household_10    Product_580\n",
      "814035   Transaction_2024_2003  Household_10  Product_63157\n",
      "814037   Transaction_2024_2003  Household_10  Product_67838\n"
     ]
    }
   ],
   "source": [
    "test_data = test_data.sort_values(by=['customer_id', 'product_id'], ascending=[True, True])\n",
    "print(test_data.head(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        customer_id  product_id\n",
      "69458             1         170\n",
      "813978            1       15693\n",
      "813974            1       20576\n",
      "813977            1       23579\n",
      "813973            1       23625\n",
      "69459             1       24334\n",
      "813975            1       24503\n",
      "407363            1       35730\n",
      "813979            1       39719\n",
      "69457             1       45719\n",
      "813980            1       47925\n",
      "813972            1       49682\n",
      "407364            1       57011\n",
      "407365            1       57942\n",
      "69460             1       64067\n",
      "813971            1       66850\n",
      "813976            1       72217\n",
      "407366            1       73323\n",
      "338989            2        2182\n",
      "813983            2        3753\n",
      "813984            2        4796\n",
      "813985            2        6493\n",
      "407367            2        7978\n",
      "813989            2        8816\n",
      "813986            2       15970\n",
      "407369            2       17770\n",
      "407371            2       28757\n",
      "407370            2       30477\n",
      "338990            2       38436\n",
      "813987            2       42748\n",
      "338991            2       44703\n",
      "813982            2       47951\n",
      "407368            2       54653\n",
      "813988            2       64586\n",
      "338992            2       71112\n",
      "813981            2       81860\n",
      "131581            3        8582\n",
      "813990            3       15725\n",
      "131580            3       20181\n",
      "131585            3       22582\n",
      "(1220706, 2)\n"
     ]
    }
   ],
   "source": [
    "test_set = test_data.drop(columns=[\"transaction_id\"])\n",
    "\n",
    "if not pd.api.types.is_numeric_dtype(test_set['customer_id']):\n",
    "    test_set['customer_id'] = test_set['customer_id'].str.replace('Household_', '').astype(int)\n",
    "\n",
    "if not pd.api.types.is_numeric_dtype(test_set['product_id']):\n",
    "    test_set['product_id'] = test_set['product_id'].str.replace('Product_', '').astype(int)\n",
    "\n",
    "test_set = test_set.sort_values(by=['customer_id', 'product_id'], ascending=[True, True])\n",
    "\n",
    "print(test_set.head(40))\n",
    "print(test_set.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Graph structure creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_nodes = purchase_data['customer_id'].unique().astype(int)\n",
    "product_nodes = purchase_data['product_id'].unique().astype(int)\n",
    "\n",
    "B = nx.Graph()\n",
    "\n",
    "# Add nodes for customers and products with the appropriate types\n",
    "for _, row in purchase_data.iterrows():\n",
    "    # Ensure the IDs are integers before creating the nodes\n",
    "    customer_id = int(row['customer_id'])\n",
    "    product_id = int(row['product_id'])\n",
    "\n",
    "    customer_node = f\"Customer_{customer_id}\"\n",
    "    product_node = f\"Product_{product_id}\"\n",
    "\n",
    "    # Add customer node (if not already in graph)\n",
    "    if customer_node not in B:\n",
    "        B.add_node(customer_node, type='customer')\n",
    "    \n",
    "    # Add product node (if not already in graph)\n",
    "    if product_node not in B:\n",
    "        B.add_node(product_node, type='product')\n",
    "    \n",
    "    # Add edge between customer and product (purchase relationship)\n",
    "    B.add_edge(customer_node, product_node, weight=row['quantity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save nodes with attributes to a file\n",
    "with open(\"nodes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict(B.nodes(data=True)), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "chunk_size = 9_000_000\n",
    "edges = list(B.edges(data=True))  # Get all edges with attributes\n",
    "\n",
    "# Save edges in chunks\n",
    "for i in range(0, len(edges), chunk_size):\n",
    "    chunk = edges[i:i + chunk_size]\n",
    "    with open(f\"edges_{i // chunk_size}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(chunk, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nodes.pkl\", \"rb\") as f:\n",
    "    nodes = pickle.load(f)\n",
    "\n",
    "B = nx.Graph() \n",
    "B.add_nodes_from(nodes.items())\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    try:\n",
    "        with open(f\"edges_{i}.pkl\", \"rb\") as f:\n",
    "            edges = pickle.load(f)\n",
    "            B.add_edges_from(edges)\n",
    "        i += 1\n",
    "    except FileNotFoundError:\n",
    "        break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer nodes: 100000\n",
      "Product nodes: 82815\n",
      "Total number of edges: 33485786\n"
     ]
    }
   ],
   "source": [
    "customer_nodes = [n for n in B.nodes if B.nodes[n].get('type') == 'customer']\n",
    "product_nodes = [n for n in B.nodes if B.nodes[n].get('type') == 'product']\n",
    "\n",
    "print(f\"Customer nodes: {len(customer_nodes)}\")  # Should be 100,000\n",
    "print(f\"Product nodes: {len(product_nodes)}\")    # Should be 82,815\n",
    "\n",
    "total_edges = B.number_of_edges()\n",
    "print(f\"Total number of edges: {total_edges}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Embedding Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(57942, {'bio': 0, 'sugar_free': 0, 'gluten_free': 0, 'halal': 0, 'reduced_sugar': 0, 'vegetarian': 0, 'vegan': 0, 'pesticide_free': 0, 'no_added_sugar': 0, 'salt_reduced': 0, 'no_added_salt': 0, 'no_artificial_flavours': 0, 'porc': 0, 'frozen': 0, 'fat_free': 0, 'reduced_fats': 0, 'fresh': 0, 'alcool': 0, 'lactose_free': 0, 'brand_key_encoded': 0.02577269959931473, 'shelf_level1_encoded': 0.39584798240990027, 'shelf_level2_encoded': 0.1804035327943097, 'shelf_level3_encoded': 0.28661262169814977})]\n"
     ]
    }
   ],
   "source": [
    "# Extract unique product IDs and their features\n",
    "product_features = purchase_data.drop_duplicates(subset=\"product_id\").set_index(\"product_id\")\n",
    "product_feature_columns = product_features.columns.drop([\"customer_id\", \"quantity\"])\n",
    "product_features = product_features[product_feature_columns].to_dict(orient=\"index\")\n",
    "\n",
    "print(list(product_features.items())[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the embedding dimension\n",
    "embedding_dim = 128\n",
    "\n",
    "# Function to handle dimensionality mismatch for product embeddings\n",
    "def get_product_embedding(product_id):\n",
    "    features = np.array(list(product_features[product_id].values()))\n",
    "    if len(features) < embedding_dim:\n",
    "        padding = np.random.rand(embedding_dim - len(features))\n",
    "        return np.concatenate([features, padding])\n",
    "    elif len(features) > embedding_dim:\n",
    "        return features[:embedding_dim]\n",
    "    return features\n",
    "\n",
    "# Initialize customer embeddings as random tensors and normalize them\n",
    "customer_embeddings = torch.randn(len(customer_nodes), embedding_dim)\n",
    "customer_embeddings = F.normalize(customer_embeddings, p=2, dim=1)  # Normalize to unit length\n",
    "\n",
    "# Initialize product embeddings using product features, normalize after padding/truncation\n",
    "product_embeddings = torch.zeros(len(product_nodes), embedding_dim)\n",
    "\n",
    "for idx, product_id in enumerate(product_nodes):\n",
    "    product_embedding = get_product_embedding(int(product_id.split('_')[1]))  # Extract product ID from the node\n",
    "    product_embeddings[idx] = torch.tensor(product_embedding, dtype=torch.float32)\n",
    "\n",
    "product_embeddings = F.normalize(product_embeddings, p=2, dim=1)  # Normalize product embeddings\n",
    "\n",
    "# Combine customer and product embeddings into a single tensor (for easier processing later)\n",
    "embeddings = torch.cat([customer_embeddings, product_embeddings], dim=0)\n",
    "\n",
    "# Convert node IDs to tensor indices for later use\n",
    "customer_node_indices = torch.tensor([i for i, n in enumerate(B.nodes) if B.nodes[n].get('type') == 'customer'])\n",
    "product_node_indices = torch.tensor([i for i, n in enumerate(B.nodes) if B.nodes[n].get('type') == 'product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings tensor: torch.Size([182815, 128])\n",
      "Customer embedding (index 10): tensor([ 0.0783,  0.1410, -0.0485,  0.0551,  0.0812, -0.0043,  0.0348, -0.0825,\n",
      "         0.0408,  0.0782, -0.0697,  0.0831, -0.0893, -0.0819, -0.0079, -0.0926,\n",
      "        -0.1070,  0.0532,  0.0763, -0.1843, -0.0144, -0.1745, -0.0685, -0.1193,\n",
      "         0.0580, -0.0565,  0.0254, -0.0339,  0.0429, -0.1232,  0.1187,  0.0838,\n",
      "         0.0879, -0.1233, -0.1376,  0.0362, -0.0118,  0.0968,  0.0216, -0.0442,\n",
      "         0.0231, -0.0466, -0.0051, -0.1075, -0.0082,  0.1044, -0.1241, -0.0916,\n",
      "        -0.1195,  0.0070,  0.1671, -0.0364, -0.0341,  0.0088, -0.0421,  0.2043,\n",
      "        -0.0045, -0.0578,  0.0057, -0.1108, -0.0250, -0.0090,  0.0726,  0.0838,\n",
      "        -0.0743,  0.0437,  0.0070,  0.1479, -0.1536,  0.1529, -0.0360,  0.1777,\n",
      "        -0.0656,  0.0684, -0.0538, -0.0521,  0.0021, -0.0711, -0.0144, -0.0978,\n",
      "         0.1119, -0.0374, -0.0377, -0.0657, -0.0483,  0.0033, -0.0365, -0.1231,\n",
      "        -0.0474,  0.0780,  0.1065,  0.1126,  0.0301,  0.0728,  0.0840, -0.0252,\n",
      "        -0.0417,  0.0829, -0.1755,  0.0472, -0.0633, -0.0320,  0.0363,  0.1044,\n",
      "        -0.0688, -0.0302,  0.0249,  0.0731, -0.0542, -0.0828, -0.0136,  0.0112,\n",
      "         0.2534, -0.1060, -0.0618,  0.0587,  0.0165, -0.1459, -0.2508, -0.0087,\n",
      "         0.0610, -0.1011,  0.0072, -0.0085,  0.0090, -0.1839, -0.1326, -0.0555])\n",
      "Product embedding (index 100000): tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 4.3253e-03, 6.6434e-02, 3.0276e-02, 4.8101e-02, 9.9509e-02,\n",
      "        7.7381e-02, 1.2789e-01, 1.8458e-02, 1.5589e-01, 1.8111e-02, 2.8054e-02,\n",
      "        8.1094e-02, 1.5779e-01, 1.3708e-01, 7.4840e-02, 8.5894e-02, 1.9622e-02,\n",
      "        6.4945e-02, 2.9802e-02, 6.1452e-02, 1.2643e-01, 8.3111e-02, 1.3175e-01,\n",
      "        1.4133e-01, 1.1488e-02, 1.6377e-01, 1.7098e-03, 3.4341e-05, 4.6087e-02,\n",
      "        3.0759e-02, 3.4687e-02, 1.1178e-01, 1.3446e-01, 1.0623e-02, 1.4676e-01,\n",
      "        4.4411e-02, 7.3750e-02, 8.7042e-02, 1.9735e-02, 1.1638e-02, 1.4000e-02,\n",
      "        1.4554e-01, 5.4545e-02, 1.3136e-01, 3.3970e-02, 5.0628e-02, 5.6516e-03,\n",
      "        1.0558e-01, 1.6167e-02, 9.5599e-02, 1.3857e-01, 1.6524e-01, 9.1429e-02,\n",
      "        4.1447e-02, 6.5551e-02, 6.1806e-02, 9.6351e-02, 6.6155e-02, 4.7112e-02,\n",
      "        3.1680e-02, 1.0099e-01, 1.4152e-01, 1.2253e-01, 1.2106e-01, 1.5255e-01,\n",
      "        2.1839e-02, 1.6384e-01, 1.6468e-01, 1.2537e-01, 8.6827e-02, 3.8024e-02,\n",
      "        8.6803e-02, 4.1968e-02, 3.5759e-02, 1.0288e-01, 1.1724e-01, 1.2726e-01,\n",
      "        9.5230e-02, 5.8446e-02, 1.0171e-01, 9.9141e-02, 1.4639e-01, 3.1438e-02,\n",
      "        4.6316e-02, 9.9176e-02, 1.5625e-01, 1.4110e-01, 1.3410e-01, 8.8279e-02,\n",
      "        3.5123e-02, 8.6981e-02, 1.1932e-01, 1.2733e-01, 1.3823e-01, 1.3234e-01,\n",
      "        6.8300e-02, 5.8427e-02, 1.1371e-01, 7.4174e-02, 2.7084e-02, 1.4736e-01,\n",
      "        4.3728e-02, 1.4008e-01, 5.9285e-02, 8.2444e-02, 2.6046e-02, 5.7590e-02,\n",
      "        1.2906e-01, 1.6506e-01])\n"
     ]
    }
   ],
   "source": [
    "# Print shape of embeddings to verify\n",
    "print(f\"Shape of embeddings tensor: {embeddings.shape}\")  # Should be (number of nodes, embedding_dim)\n",
    "\n",
    "# Example: Print embedding for a specific customer and a specific product\n",
    "customer_index = 10\n",
    "product_index = len(customer_nodes)  # Index of the product (it follows customer nodes in the embeddings tensor)\n",
    "\n",
    "# Print the embeddings\n",
    "print(f\"Customer embedding (index {customer_index}): {customer_embeddings[customer_index]}\")\n",
    "print(f\"Product embedding (index {product_index}): {product_embeddings[product_index - len(customer_nodes)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Graph Propagation Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingPropagationLayer(nn.Module):\n",
    "    def __init__(self, embedding_dim, alpha=0.2):\n",
    "        super(EmbeddingPropagationLayer, self).__init__()\n",
    "        # Trainable weight matrices for embedding transformation and interaction\n",
    "        self.W1 = nn.Parameter(torch.randn(embedding_dim, embedding_dim))\n",
    "        self.W2 = nn.Parameter(torch.randn(embedding_dim, embedding_dim))\n",
    "        self.alpha = alpha  # LeakyReLU coefficient\n",
    "\n",
    "    def forward(self, user_embeddings, item_embeddings, adjacency_matrix):\n",
    "        \"\"\"\n",
    "        Perform one layer of embedding propagation between users and items.\n",
    "        \"\"\"\n",
    "        # Normalize adjacency matrix (graph Laplacian scaling factor)\n",
    "        row_sum = adjacency_matrix.sum(dim=1, keepdim=True)\n",
    "        col_sum = adjacency_matrix.sum(dim=0, keepdim=True)\n",
    "        scaling_factor = torch.sqrt(row_sum * col_sum) + 1e-8\n",
    "        normalized_adj = adjacency_matrix / scaling_factor\n",
    "\n",
    "        # Compute messages from items to users\n",
    "        message_item_to_user = self.compute_message(item_embeddings, user_embeddings, normalized_adj.T)\n",
    "\n",
    "        # Aggregate messages for users\n",
    "        updated_user_embeddings = self.aggregate_embeddings(user_embeddings, message_item_to_user)\n",
    "\n",
    "        # Compute messages from users to items\n",
    "        message_user_to_item = self.compute_message(user_embeddings, item_embeddings, normalized_adj)\n",
    "\n",
    "        # Aggregate messages for items\n",
    "        updated_item_embeddings = self.aggregate_embeddings(item_embeddings, message_user_to_item)\n",
    "\n",
    "        return updated_user_embeddings, updated_item_embeddings\n",
    "\n",
    "    def compute_message(self, source_embeddings, target_embeddings, adjacency_matrix):\n",
    "        \"\"\"\n",
    "        Compute messages from source nodes (e.g., items) to target nodes (e.g., users).\n",
    "        \"\"\"\n",
    "        # Interaction term between source and target embeddings (element-wise multiplication)\n",
    "        interaction_term = source_embeddings.unsqueeze(1) * target_embeddings.unsqueeze(0)\n",
    "\n",
    "        # Message encoding (Equation 3 in the paper)\n",
    "        message = torch.matmul(source_embeddings, self.W1) + torch.matmul(interaction_term, self.W2)\n",
    "        \n",
    "        # Aggregate the messages with the adjacency matrix\n",
    "        message = torch.bmm(adjacency_matrix.unsqueeze(2), message)  # Adjust shape for broadcasting\n",
    "\n",
    "        return message\n",
    "\n",
    "    def aggregate_embeddings(self, embeddings, message):\n",
    "        \"\"\"\n",
    "        Aggregate messages and update embeddings with LeakyReLU (Equation 4 in the paper).\n",
    "        \"\"\"\n",
    "        aggregated_message = message.sum(dim=1) + embeddings  # Self-connection included\n",
    "        updated_embeddings = F.leaky_relu(aggregated_message, negative_slope=self.alpha)\n",
    "\n",
    "        return updated_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEmbeddingPropagation(nn.Module):\n",
    "    def __init__(self, user_embeddings, item_embeddings, adjacency_matrix, embedding_dim=128, num_layers=3, sample_size=50, alpha=0.2):\n",
    "        super(GraphEmbeddingPropagation, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.sample_size = sample_size  # Number of neighbors to sample\n",
    "        self.alpha = alpha  # LeakyReLU coefficient\n",
    "\n",
    "        # Initialize user and item embeddings as trainable parameters\n",
    "        self.user_embeddings = nn.Parameter(torch.tensor(user_embeddings, dtype=torch.float32))\n",
    "        self.item_embeddings = nn.Parameter(torch.tensor(item_embeddings, dtype=torch.float32))\n",
    "\n",
    "        # Store adjacency matrix as sparse for memory efficiency\n",
    "        self.adjacency_matrix = adjacency_matrix.coalesce()  # Convert to sparse format\n",
    "\n",
    "        # Stack embedding propagation layers\n",
    "        self.layers = nn.ModuleList([EmbeddingPropagationLayer(embedding_dim, alpha) for _ in range(num_layers)])\n",
    "\n",
    "    def sample_neighbors(self, node_idx, num_neighbors):\n",
    "        \"\"\"\n",
    "        Sample a fixed number of neighbors for a given node index.\n",
    "        \"\"\"\n",
    "        neighbors = self.adjacency_matrix.indices()[1][self.adjacency_matrix.indices()[0] == node_idx]\n",
    "        if len(neighbors) > num_neighbors:\n",
    "            neighbors = random.sample(neighbors.tolist(), num_neighbors)\n",
    "        return neighbors\n",
    "\n",
    "    def create_sampled_adjacency(self, batch_nodes):\n",
    "        \"\"\"\n",
    "        Create a sampled adjacency matrix for the batch nodes.\n",
    "        \"\"\"\n",
    "        indices = []\n",
    "        values = []\n",
    "\n",
    "        for node in batch_nodes:\n",
    "            neighbors = self.sample_neighbors(node, self.sample_size)\n",
    "            for neighbor in neighbors:\n",
    "                indices.append([node, neighbor])\n",
    "                values.append(self.adjacency_matrix[node, neighbor].item())\n",
    "\n",
    "        # Convert to sparse adjacency matrix\n",
    "        indices = torch.tensor(indices, dtype=torch.long).t()  # Transpose for PyTorch format\n",
    "        values = torch.tensor(values, dtype=torch.float32)\n",
    "        sampled_adj = torch.sparse_coo_tensor(indices, values, self.adjacency_matrix.size())\n",
    "        return sampled_adj.coalesce()\n",
    "\n",
    "    def forward(self, batch_nodes):\n",
    "        \"\"\"\n",
    "        Perform multi-layer embedding propagation with neighbor sampling and message passing.\n",
    "        \"\"\"\n",
    "        # Initialize embeddings\n",
    "        user_embeddings, item_embeddings = self.user_embeddings, self.item_embeddings\n",
    "\n",
    "        # Create sampled adjacency matrix\n",
    "        sampled_adj = self.create_sampled_adjacency(batch_nodes)\n",
    "\n",
    "        # Sequentially apply each embedding propagation layer\n",
    "        for layer in self.layers:\n",
    "            user_embeddings, item_embeddings = layer(user_embeddings, item_embeddings, sampled_adj)\n",
    "\n",
    "        return user_embeddings, item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size=64, num_layers=3, dropout_ratio=0.1, p1=0.1, p2=0.0):\n",
    "        super(NGCF, self).__init__()\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
    "        \n",
    "        # Define the layer transformations\n",
    "        self.weights = nn.ModuleList([nn.Linear(embedding_size, embedding_size) for _ in range(num_layers)])\n",
    "        \n",
    "        # Initialize with Xavier initialization\n",
    "        self.apply(self.xavier_init)\n",
    "        \n",
    "        # Dropout rates\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        \n",
    "        # Final linear layer to map concatenated embeddings back to the embedding size\n",
    "        self.final_user_linear = nn.Linear(embedding_size * (num_layers + 1), embedding_size)\n",
    "        self.final_item_linear = nn.Linear(embedding_size * (num_layers + 1), embedding_size)\n",
    "\n",
    "    def xavier_init(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, user_indices, item_indices, negative_item_indices):\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        item_emb = self.item_embedding(item_indices)\n",
    "        negative_item_emb = self.item_embedding(negative_item_indices)\n",
    "\n",
    "        all_user_embeddings = [user_emb]\n",
    "        all_item_embeddings = [item_emb]\n",
    "        \n",
    "        # Propagate through layers\n",
    "        for layer in range(self.num_layers):\n",
    "            user_emb = F.dropout(user_emb, p=self.p1, training=self.training)\n",
    "            item_emb = F.dropout(item_emb, p=self.p1, training=self.training)\n",
    "            \n",
    "            user_emb = F.relu(self.weights[layer](user_emb))\n",
    "            item_emb = F.relu(self.weights[layer](item_emb))\n",
    "            \n",
    "            all_user_embeddings.append(user_emb)\n",
    "            all_item_embeddings.append(item_emb)\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        user_final_emb = torch.cat(all_user_embeddings, dim=-1)  # Shape: (batch_size, embedding_size * (num_layers + 1))\n",
    "        item_final_emb = torch.cat(all_item_embeddings, dim=-1)  # Shape: (batch_size, embedding_size * (num_layers + 1))\n",
    "\n",
    "        # Final projection to embedding size\n",
    "        user_final_emb = self.final_user_linear(user_final_emb)\n",
    "        item_final_emb = self.final_item_linear(item_final_emb)\n",
    "\n",
    "        # Apply dropout to final embeddings\n",
    "        if self.p2 > 0:\n",
    "            user_final_emb = F.dropout(user_final_emb, p=self.p2, training=self.training)\n",
    "            item_final_emb = F.dropout(item_final_emb, p=self.p2, training=self.training)\n",
    "\n",
    "        # Compute predictions: positive items and negative items\n",
    "        prediction_pos = torch.sum(user_final_emb * item_final_emb, dim=-1)\n",
    "        prediction_neg = torch.sum(user_final_emb * negative_item_emb, dim=-1)\n",
    "\n",
    "        return prediction_pos, prediction_neg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mappings\n",
    "customer_to_int = {}\n",
    "product_to_int = {}\n",
    "\n",
    "# Go through the graph and create mappings based on original IDs\n",
    "for node in B.nodes:\n",
    "    if B.nodes[node].get('type') == 'customer' and node.startswith('Customer_'):\n",
    "        customer_id = int(node.split('_')[1])\n",
    "        customer_to_int[node] = customer_id\n",
    "    elif B.nodes[node].get('type') == 'product' and node.startswith('Product_'):\n",
    "        product_id = int(node.split('_')[1])\n",
    "        product_to_int[node] = product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_negative_sampling(user_idx, positive_items, all_items, product_embeddings, num_negatives=5, subset_size=1000):\n",
    "    \"\"\"\n",
    "    Perform hard negative sampling efficiently with subset sampling and optimized cosine similarity.\n",
    "    \"\"\"\n",
    "    # Use GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    product_embeddings = product_embeddings.to(device)\n",
    "\n",
    "    # Efficiently sample a subset of all_items\n",
    "    if isinstance(all_items, range):\n",
    "        subset_indices = torch.randint(0, len(all_items), (min(subset_size, len(all_items)),), device=device)\n",
    "    else:\n",
    "        subset_indices = torch.tensor(\n",
    "            random.sample(all_items, min(subset_size, len(all_items))),\n",
    "            device=device,\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "    # Exclude positive items from the subset\n",
    "    positive_items_tensor = torch.tensor(positive_items, device=device, dtype=torch.long)\n",
    "    mask = ~torch.isin(subset_indices, positive_items_tensor)\n",
    "    filtered_subset = subset_indices[mask]\n",
    "\n",
    "    # Ensure at least `num_negatives` items are available\n",
    "    if len(filtered_subset) < num_negatives:\n",
    "        print(f\"Warning: Not enough filtered negatives, reducing to {len(filtered_subset)}\")\n",
    "        num_negatives = len(filtered_subset)\n",
    "\n",
    "    # Get embeddings for positive items and the filtered subset\n",
    "    positive_embeddings = product_embeddings[positive_items_tensor]\n",
    "    subset_embeddings = product_embeddings[filtered_subset]\n",
    "\n",
    "    # Normalize embeddings for cosine similarity calculation\n",
    "    positive_embeddings = F.normalize(positive_embeddings, dim=1)\n",
    "    subset_embeddings = F.normalize(subset_embeddings, dim=1)\n",
    "\n",
    "    # Compute cosine similarities between subset and positive items\n",
    "    similarities = torch.mm(subset_embeddings, positive_embeddings.T)  # (|subset|, |positive_items|)\n",
    "\n",
    "    # Compute mean similarity for each sampled item in the subset\n",
    "    mean_similarities = similarities.mean(dim=1)  # (|subset|,)\n",
    "\n",
    "    # Select the top-k hardest negatives (lowest mean similarity)\n",
    "    hard_negatives_indices = torch.topk(mean_similarities, num_negatives, largest=False).indices\n",
    "\n",
    "    # Map back to the original item indices\n",
    "    hard_negatives = filtered_subset[hard_negatives_indices]\n",
    "\n",
    "    return hard_negatives.tolist()\n",
    "\n",
    "def generate_negative_samples(user_indices, pos_item_indices, all_item_indices, product_embeddings, num_negatives=10, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generates negative samples for the given users and items using hard_negative_sampling.\n",
    "    Ensures that negative samples are within valid bounds and handles edge cases gracefully.\n",
    "    \"\"\"\n",
    "    # Ensure all inputs are on the correct device (GPU or CPU)\n",
    "    user_indices = user_indices.to(device)\n",
    "    pos_item_indices = pos_item_indices.to(device)\n",
    "    all_item_indices = all_item_indices.to(device)\n",
    "\n",
    "    negative_samples = []\n",
    "\n",
    "    for user, pos_item in zip(user_indices, pos_item_indices):\n",
    "        try:\n",
    "            # Adjust product item indices to match embedding index space\n",
    "            pos_item_adjusted = pos_item + 99999  # Add 99,999 to match the embedding indices for products\n",
    "            \n",
    "            # Perform hard negative sampling for this user\n",
    "            negatives = hard_negative_sampling(\n",
    "                user_idx=user.item(),\n",
    "                positive_items=[pos_item_adjusted.item()],  # Use adjusted index for products\n",
    "                all_items=all_item_indices.tolist(),\n",
    "                product_embeddings=product_embeddings,\n",
    "                num_negatives=num_negatives\n",
    "            )\n",
    "\n",
    "            # Ensure the output length matches the requested number of negatives\n",
    "            if len(negatives) < num_negatives:\n",
    "                # Fill with random negatives if hard sampling didn't return enough\n",
    "                remaining_negatives = num_negatives - len(negatives)\n",
    "                additional_negatives = random.sample(\n",
    "                    list(set(all_item_indices.tolist()) - {pos_item_adjusted.item()}),\n",
    "                    remaining_negatives\n",
    "                )\n",
    "                negatives.extend(additional_negatives)\n",
    "\n",
    "            negative_samples.append(negatives)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle any errors during sampling\n",
    "            print(f\"Error generating negatives for user {user.item()}, item {pos_item.item()}: {e}\")\n",
    "            # Add random negatives as a fallback\n",
    "            fallback_negatives = random.sample(\n",
    "                list(set(all_item_indices.tolist()) - {pos_item_adjusted.item()}),\n",
    "                num_negatives\n",
    "            )\n",
    "            negative_samples.append(fallback_negatives)\n",
    "\n",
    "    # Convert the list of negatives into a tensor\n",
    "    return torch.tensor(negative_samples, device=device)\n",
    "\n",
    "def parallel_negative_sampling(user_indices, item_indices, all_item_indices, max_neg_samples=5, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate negative samples efficiently using GPU-based tensor operations.\n",
    "    Args:\n",
    "        user_indices (torch.Tensor): The user indices for the batch.\n",
    "        item_indices (torch.Tensor): The item indices for the batch.\n",
    "        all_item_indices (torch.Tensor): The unique list of all item indices.\n",
    "        max_neg_samples (int): The maximum number of negative samples to generate per user-item pair.\n",
    "        device (str): Device to run the computations ('cuda' or 'cpu').\n",
    "    Returns:\n",
    "        torch.Tensor: The negative item indices for each user-item pair.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the data is on the correct device (GPU or CPU)\n",
    "    user_indices = user_indices.to(device)\n",
    "    item_indices = item_indices.to(device)\n",
    "    all_item_indices = all_item_indices.to(device)\n",
    "\n",
    "    def generate_negatives(user_idx, item_idx):\n",
    "        # Sample random negatives (ensuring no overlap with the positive item)\n",
    "        neg_samples = all_item_indices[torch.randint(len(all_item_indices), (max_neg_samples,)).to(device)]\n",
    "        neg_samples = neg_samples[neg_samples != item_idx]  # Exclude the positive item\n",
    "        \n",
    "        # If less than required, keep sampling until we fill max_neg_samples\n",
    "        while len(neg_samples) < max_neg_samples:\n",
    "            additional_neg_samples = all_item_indices[torch.randint(len(all_item_indices), (max_neg_samples - len(neg_samples),)).to(device)] \n",
    "            neg_samples = torch.cat((neg_samples, additional_neg_samples), dim=0)\n",
    "            neg_samples = neg_samples[neg_samples != item_idx]\n",
    "        \n",
    "        return neg_samples[:max_neg_samples]\n",
    "\n",
    "    # Parallelizing the negative sampling for each user-item pair using multiprocessing\n",
    "    def negative_sampling_worker(start_idx, end_idx):\n",
    "        negatives_batch = []\n",
    "        for idx in range(start_idx, end_idx):\n",
    "            user_idx = user_indices[idx]\n",
    "            item_idx = item_indices[idx]\n",
    "            neg_samples = generate_negatives(user_idx, item_idx)\n",
    "            negatives_batch.append(neg_samples)\n",
    "        return negatives_batch\n",
    "\n",
    "    num_workers = mp.cpu_count()  # Use all available CPU cores\n",
    "    chunk_size = len(user_indices) // num_workers\n",
    "    chunks = [(i * chunk_size, (i + 1) * chunk_size) for i in range(num_workers)]\n",
    "\n",
    "    # Use multiprocessing to distribute the negative sampling across the workers\n",
    "    with mp.Pool(num_workers) as pool:\n",
    "        results = pool.starmap(negative_sampling_worker, chunks)\n",
    "    \n",
    "    # Flatten the results\n",
    "    all_negatives = torch.cat([torch.cat(res, dim=0) for res in results], dim=0)\n",
    "\n",
    "    return all_negatives\n",
    "\n",
    "# Training DataLoader\n",
    "def data_loader(user_indices, pos_item_indices, neg_item_indices, batch_size):\n",
    "    dataset = TensorDataset(user_indices, pos_item_indices, neg_item_indices)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(B, batch_size=10000, model=None, item_embeddings=None):\n",
    "    \"\"\"\n",
    "    Prepares the training data with positive and dynamically generated hard negative samples.\n",
    "    Optimized by caching neighbors and avoiding redundant lookups.\n",
    "    \"\"\"\n",
    "    if item_embeddings is None:\n",
    "        raise ValueError(\"Item embeddings are None. Ensure that the embeddings are properly initialized.\")\n",
    "    \n",
    "    # Map user and item IDs to integers\n",
    "    user_to_int = {user: idx for idx, user in enumerate(n for n in B.nodes if B.nodes[n].get('type') == 'customer')}\n",
    "    item_to_int = {item: idx for idx, item in enumerate(n for n in B.nodes if B.nodes[n].get('type') == 'product')}\n",
    "    \n",
    "    # Extract users and items\n",
    "    users = list(user_to_int.keys())\n",
    "    all_items = torch.tensor(list(item_to_int.values()), dtype=torch.long)  # All item IDs as tensor\n",
    "    \n",
    "    # Cache neighbors for all users (assuming these are static across batches)\n",
    "    user_neighbors = {user: list(B.neighbors(user)) for user in users}\n",
    "\n",
    "    # Initialize lists to collect results\n",
    "    positive_users, positive_items = [], []\n",
    "    negative_users, negative_items = [], []\n",
    "\n",
    "    # Process users in batches\n",
    "    for i in range(0, len(users), batch_size):\n",
    "        batch_users = users[i:i + batch_size]\n",
    "        \n",
    "        # Create positive interactions (observed user-item pairs)\n",
    "        batch_positive_users, batch_positive_items = [], []\n",
    "        for user in batch_users:\n",
    "            neighbors = user_neighbors[user]\n",
    "            for item in neighbors:\n",
    "                if B[user][item].get('weight', 0) > 0:  # Valid interaction\n",
    "                    batch_positive_users.append(user_to_int[user])\n",
    "                    batch_positive_items.append(item_to_int[item])\n",
    "        \n",
    "        positive_users.extend(batch_positive_users)\n",
    "        positive_items.extend(batch_positive_items)\n",
    "        \n",
    "        # Efficient negative sampling for the batch\n",
    "        for user in batch_users:\n",
    "            # Get positive items for the user (those they've interacted with)\n",
    "            positive_items_for_user = [item_to_int[item] for item in user_neighbors[user] if B[user][item].get('weight', 0) > 0]\n",
    "            \n",
    "            # Get unobserved items efficiently by creating a mask\n",
    "            positive_items_set = set(positive_items_for_user)\n",
    "            unobserved_items = all_items[~torch.isin(all_items, torch.tensor(positive_items_for_user, dtype=torch.long))]\n",
    "\n",
    "            # Adjust the indices for negative sampling to match embeddings\n",
    "            unobserved_items_adjusted = unobserved_items + 99999  # Add 99,999 to product indices\n",
    "            \n",
    "            # Sample hard negatives for the entire batch of users at once\n",
    "            sampled_negatives = hard_negative_sampling(user_to_int[user], positive_items_for_user, unobserved_items_adjusted.tolist(), item_embeddings)\n",
    "            \n",
    "            # Collect the negative samples\n",
    "            for neg_item in sampled_negatives:\n",
    "                negative_users.append(user_to_int[user])\n",
    "                negative_items.append(neg_item)\n",
    "\n",
    "    # Ensure there are sufficient positive and negative samples\n",
    "    if not positive_users or not negative_users:\n",
    "        raise ValueError(\"Insufficient positive or negative samples generated.\")\n",
    "\n",
    "    # Convert to tensors for use in training\n",
    "    positive_users_tensor = torch.tensor(positive_users, dtype=torch.long)\n",
    "    positive_items_tensor = torch.tensor(positive_items, dtype=torch.long)\n",
    "    negative_users_tensor = torch.tensor(negative_users, dtype=torch.long)\n",
    "    negative_items_tensor = torch.tensor(negative_items, dtype=torch.long)\n",
    "    \n",
    "    # Return the dataset\n",
    "    return data_loader(positive_users_tensor, positive_items_tensor, negative_items_tensor, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(B, batch_size=10000):\n",
    "    # Map user and item IDs to integers\n",
    "    user_to_int = {user: idx for idx, user in enumerate(n for n in B.nodes if B.nodes[n].get('type') == 'customer')}\n",
    "    item_to_int = {item: idx for idx, item in enumerate(n for n in B.nodes if B.nodes[n].get('type') == 'product')}\n",
    "\n",
    "    # Extract users as integers\n",
    "    users = list(user_to_int.keys())\n",
    "\n",
    "    # Initialize lists to collect results\n",
    "    test_users, test_items = [], []\n",
    "\n",
    "    # Precompute neighbors for all users in the graph to avoid redundant calculations\n",
    "    user_neighbors = {user: list(B.neighbors(user)) for user in users}\n",
    "    \n",
    "    # Process users in batches to save memory\n",
    "    for i in range(0, len(users), batch_size):\n",
    "        batch_users = users[i:i + batch_size]\n",
    "        \n",
    "        # Create test samples for the current batch\n",
    "        for user in batch_users:\n",
    "            neighbors = user_neighbors[user]\n",
    "            for item in neighbors:\n",
    "                # Check if the interaction is valid (positive weight)\n",
    "                if B[user][item].get('weight', 0) > 0:\n",
    "                    test_users.append(user_to_int[user])\n",
    "                    test_items.append(item_to_int[item])\n",
    "\n",
    "    if not test_users:\n",
    "        raise ValueError(\"No test samples found in the dataset.\")\n",
    "\n",
    "    # Convert to tensors\n",
    "    test_user_indices = torch.tensor(test_users, dtype=torch.long)\n",
    "    test_item_indices = torch.tensor(test_items, dtype=torch.long)\n",
    "    \n",
    "    return test_user_indices, test_item_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(y_pred_pos, y_pred_neg, lambda_reg=1e-5):\n",
    "    \"\"\"\n",
    "    BPR loss function\n",
    "    Args:\n",
    "        y_pred_pos: predicted score for positive item\n",
    "        y_pred_neg: predicted score for negative item\n",
    "        lambda_reg: L2 regularization strength\n",
    "    \"\"\"\n",
    "    loss = -torch.log(torch.sigmoid(y_pred_pos - y_pred_neg)).mean()\n",
    "    reg_loss = lambda_reg * (y_pred_pos.norm(2) + y_pred_neg.norm(2))\n",
    "    return loss + reg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_at_k(predictions, ground_truth, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Hit@K for recommendations.\n",
    "    \n",
    "    Args:\n",
    "        predictions: The predicted scores for items (e.g., user-item pairs).\n",
    "        ground_truth: The true items that the user interacted with.\n",
    "        k: The number of top items to consider for the hit calculation.\n",
    "\n",
    "    Returns:\n",
    "        hit@k score: The percentage of times the true item is in the top-k recommendations.\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    for i in range(len(predictions)):\n",
    "        # Ensure that predictions[i] is a 1D tensor (with items to rank)\n",
    "        if predictions[i].dim() == 1:\n",
    "            num_items = predictions[i].size(0)\n",
    "        else:\n",
    "            # Skip if the prediction is not a tensor with the expected dimensions\n",
    "            continue\n",
    "        \n",
    "        # If the number of items is fewer than k, use all items\n",
    "        if num_items < k:\n",
    "            top_k_items = predictions[i].topk(num_items).indices.tolist()\n",
    "        else:\n",
    "            top_k_items = predictions[i].topk(k).indices.tolist()\n",
    "\n",
    "        # Check if the true item is in the top k predictions\n",
    "        if ground_truth[i] in top_k_items:\n",
    "            hits += 1\n",
    "\n",
    "    hit_at_k = hits / len(predictions)\n",
    "    return hit_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    scaler = GradScaler()  # For mixed precision training\n",
    "    \n",
    "    for user_indices, item_indices, negative_item_indices in train_loader:\n",
    "        # Move data to the device in advance if it's not already there\n",
    "        user_indices = user_indices.to(device)\n",
    "        item_indices = item_indices.to(device)\n",
    "        negative_item_indices = negative_item_indices.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():  # Enable mixed precision\n",
    "            # Forward pass\n",
    "            positive_preds, negative_preds = model(user_indices, item_indices, negative_item_indices)\n",
    "\n",
    "            # Compute BPR loss\n",
    "            loss = bpr_loss(positive_preds, negative_preds, lambda_reg=1e-5)\n",
    "\n",
    "        # Backpropagate and optimize\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(model, test_loader, device, k=10):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for user_indices, item_indices, _ in test_loader:\n",
    "            # Move data to device in advance\n",
    "            user_indices = user_indices.to(device)\n",
    "            item_indices = item_indices.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            positive_preds, _ = model(user_indices, item_indices, item_indices)\n",
    "            predictions.append(positive_preds)\n",
    "\n",
    "            # Collect ground truth (true items)\n",
    "            ground_truth.append(item_indices)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    predictions = torch.cat(predictions, dim=0).cpu()  # Move only once after the loop\n",
    "    ground_truth = torch.cat(ground_truth, dim=0).cpu()\n",
    "\n",
    "    # Calculate Hit@10\n",
    "    return hit_at_k(predictions, ground_truth, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the device for GPU usage (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device in use: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of users and items\n",
    "num_users = [n for n in B.nodes if B.nodes[n].get('type') == 'customer']\n",
    "num_items = [n for n in B.nodes if B.nodes[n].get('type') == 'product']\n",
    "\n",
    "embedding_size = 64\n",
    "num_layers = 3 \n",
    "batch_size = 1024\n",
    "learning_rate = 0.001\n",
    "l2_reg = 1e-5\n",
    "dropout = 0.1\n",
    "node_dropout = 0.1\n",
    "epochs = 100\n",
    "patience = 10  # Early stopping patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[166], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m batch_size_data_prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m      8\u001b[0m mp\u001b[38;5;241m.\u001b[39mset_start_method(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 10\u001b[0m train_user_indices, train_item_indices, train_negative_item_indices \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_data_prep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproduct_embeddings\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m test_user_indices, test_item_indices \u001b[38;5;241m=\u001b[39m prepare_test_data(B, batch_size\u001b[38;5;241m=\u001b[39mbatch_size_data_prep)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Downsample for faster experimentation (optional)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[153], line 53\u001b[0m, in \u001b[0;36mprepare_data\u001b[1;34m(B, batch_size, model, item_embeddings)\u001b[0m\n\u001b[0;32m     50\u001b[0m unobserved_items_adjusted \u001b[38;5;241m=\u001b[39m unobserved_items \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m99999\u001b[39m  \u001b[38;5;66;03m# Add 99,999 to product indices\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Sample hard negatives for the entire batch of users at once\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m sampled_negatives \u001b[38;5;241m=\u001b[39m \u001b[43mhard_negative_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive_items_for_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munobserved_items_adjusted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Collect the negative samples\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m neg_item \u001b[38;5;129;01min\u001b[39;00m sampled_negatives:\n",
      "Cell \u001b[1;32mIn[152], line 7\u001b[0m, in \u001b[0;36mhard_negative_sampling\u001b[1;34m(user_idx, positive_items, all_items, product_embeddings, num_negatives, subset_size)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Use GPU if available\u001b[39;00m\n\u001b[0;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m product_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mproduct_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Efficiently sample a subset of all_items\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(all_items, \u001b[38;5;28mrange\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # Ensure errors are reported synchronously\n",
    "\n",
    "# Initialize data preparation and model setup (same as your code)\n",
    "\n",
    "# Prepare data, assuming prepare_data() and prepare_test_data() functions are properly defined\n",
    "batch_size_data_prep = 10000\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "train_user_indices, train_item_indices, train_negative_item_indices = prepare_data(\n",
    "    B, batch_size=batch_size_data_prep, item_embeddings=product_embeddings\n",
    ")\n",
    "test_user_indices, test_item_indices = prepare_test_data(B, batch_size=batch_size_data_prep)\n",
    "\n",
    "# Downsample for faster experimentation (optional)\n",
    "sample_fraction = 0.1\n",
    "num_samples = min(int(sample_fraction * len(train_user_indices)), len(train_user_indices))\n",
    "train_sample_indices = torch.randperm(len(train_user_indices))[:num_samples]\n",
    "\n",
    "# Split into train/val sets (same as your code)\n",
    "train_split_fraction = 0.8\n",
    "num_train_samples = int(train_split_fraction * num_samples)\n",
    "permuted_indices = torch.randperm(num_samples)\n",
    "\n",
    "train_indices = train_sample_indices[permuted_indices[:num_train_samples]]\n",
    "val_indices = train_sample_indices[permuted_indices[num_train_samples:]]\n",
    "\n",
    "# Ensure alignment between train and validation sets\n",
    "train_user_indices = train_user_indices[train_indices]\n",
    "train_item_indices = train_item_indices[train_indices]\n",
    "train_negative_item_indices = train_negative_item_indices[train_indices]\n",
    "\n",
    "val_user_indices = train_user_indices[val_indices]\n",
    "val_item_indices = train_item_indices[val_indices]\n",
    "val_negative_item_indices = train_negative_item_indices[val_indices]\n",
    "\n",
    "# Combine unique item indices for negative sampling\n",
    "all_item_indices = torch.unique(torch.cat((train_item_indices, train_negative_item_indices)))\n",
    "\n",
    "# Move product embeddings and data to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "product_embeddings = product_embeddings.to(device)\n",
    "\n",
    "# Ensure indices are within the range of product embeddings\n",
    "max_index = product_embeddings.size(0) - 1\n",
    "assert torch.all(train_user_indices <= max_index), \"User indices are out of bounds.\"\n",
    "assert torch.all(train_item_indices <= max_index), \"Item indices are out of bounds.\"\n",
    "assert torch.all(train_negative_item_indices <= max_index), \"Negative item indices are out of bounds.\"\n",
    "\n",
    "train_user_indices = train_user_indices.to(device)\n",
    "train_item_indices = train_item_indices.to(device)\n",
    "train_negative_item_indices = train_negative_item_indices.to(device)\n",
    "\n",
    "val_user_indices = val_user_indices.to(device)\n",
    "val_item_indices = val_item_indices.to(device)\n",
    "val_negative_item_indices = val_negative_item_indices.to(device)\n",
    "\n",
    "test_user_indices = test_user_indices.to(device)\n",
    "test_item_indices = test_item_indices.to(device)\n",
    "\n",
    "# Negative sampling function (assuming it's properly defined)\n",
    "train_negative_item_indices = parallel_negative_sampling(\n",
    "    train_user_indices, train_item_indices, all_item_indices, max_neg_samples=5\n",
    ")\n",
    "val_negative_item_indices = parallel_negative_sampling(\n",
    "    val_user_indices, val_item_indices, all_item_indices, max_neg_samples=5\n",
    ")\n",
    "\n",
    "# Create DataLoaders for training, validation, and testing\n",
    "train_loader = data_loader(train_user_indices, train_item_indices, train_negative_item_indices, batch_size_data_prep)\n",
    "val_loader = data_loader(val_user_indices, val_item_indices, val_negative_item_indices, batch_size_data_prep)\n",
    "\n",
    "test_dataset = TensorDataset(test_user_indices, test_item_indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size_data_prep, shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NGCF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Instantiate the model with the fixed hyperparameters\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNGCF\u001b[49m(\n\u001b[0;32m      3\u001b[0m     num_users\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(num_users),\n\u001b[0;32m      4\u001b[0m     num_items\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(num_items),\n\u001b[0;32m      5\u001b[0m     embedding_size\u001b[38;5;241m=\u001b[39membedding_size,\n\u001b[0;32m      6\u001b[0m     num_layers\u001b[38;5;241m=\u001b[39mnum_layers,\n\u001b[0;32m      7\u001b[0m     dropout_ratio\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[0;32m      8\u001b[0m     p1\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[0;32m      9\u001b[0m     p2\u001b[38;5;241m=\u001b[39mnode_dropout,\n\u001b[0;32m     10\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Define optimizer with the fixed learning rate and L2 regularization\u001b[39;00m\n\u001b[0;32m     13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39ml2_reg)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NGCF' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate the model with the fixed hyperparameters\n",
    "model = NGCF(\n",
    "    num_users=len(num_users),\n",
    "    num_items=len(num_items),\n",
    "    embedding_size=embedding_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout_ratio=dropout,\n",
    "    p1=dropout,\n",
    "    p2=node_dropout,\n",
    ").to(device)\n",
    "\n",
    "# Define optimizer with the fixed learning rate and L2 regularization\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
    "\n",
    "# Early stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "best_hit_at_10 = 0.0  # For tracking Hit@10 improvement\n",
    "epochs_since_improvement = 0\n",
    "\n",
    "# Path to save the model\n",
    "save_path = \"best_ngcf_model.pth\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    accumulation_steps = 4  # Accumulate gradients over 4 mini-batches\n",
    "\n",
    "    for batch_idx, (users, pos_items, neg_items) in enumerate(train_loader):\n",
    "        # Move data to GPU, non-blocking for efficiency\n",
    "        users = users.to(device, non_blocking=True)\n",
    "        pos_items = pos_items.to(device, non_blocking=True)\n",
    "        neg_items = neg_items.to(device, non_blocking=True)\n",
    "        \n",
    "        # Zero gradients (before accumulating)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        positive_preds, negative_preds = model(users, pos_items, neg_items)\n",
    "        \n",
    "        # Compute BPR loss\n",
    "        loss = bpr_loss(positive_preds, negative_preds, lambda_reg=1e-5)\n",
    "        \n",
    "        # Backpropagation (but don't optimize yet)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights every `accumulation_steps` batches\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()  # Reset gradients after step\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    # Average loss for the epoch\n",
    "    train_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Validate less frequently (e.g., every 5 epochs)\n",
    "    if (epoch + 1) % 5 == 0 or epoch == epochs - 1:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = evaluate(model, val_loader, device)\n",
    "            hit_at_10_score = evaluate(model, val_loader, device, k=10)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss:.4f}, Hit@10: {hit_at_10_score:.4f}\")\n",
    "\n",
    "        # Save model if improved\n",
    "        if val_loss < best_val_loss or hit_at_10_score > best_hit_at_10:\n",
    "            best_val_loss = val_loss\n",
    "            best_hit_at_10 = hit_at_10_score\n",
    "            epochs_since_improvement = 0\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_hit_at_10': best_hit_at_10\n",
    "            }, save_path)\n",
    "            print(f\"Model saved to {save_path}\")\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "            if epochs_since_improvement >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}.\")\n",
    "                break\n",
    "\n",
    "# Final Test Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_hit_at_10 = evaluate(model, test_loader, device, k=10)\n",
    "print(f\"Final Hit@10: {final_hit_at_10:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate frequency model on whole test data using hitrate@10\n",
    "\n",
    "The aim here is to assess how relevant our 10 product recommendations are. To do this, we calculate the percentage of these recommendations that are actually purchased by the customer.\n",
    "\n",
    "In order to be precise, we describe here the formula for the computation of the score **hitrate@10**.\n",
    "Let us introduce two vectors:\n",
    "+ $(a_i)_{1 \\le i \\le N}$ with $N \\in \\mathbb{N}^*$ the products purchased by a customer during an order,\n",
    "+ $(y_i)_{1 \\le i \\le 10}$ the $10$ predicted products.\n",
    "\n",
    "Let us remark that $N$ is not necessarily equal to $10$. Then we have the following formula:\n",
    "\n",
    "\n",
    "$$HitRate@K(a,y) = \\frac{1}{\\min(N,10)}\\sum_{i=1}^{10} \\mathbb{1}_{y_i \\in \\{a_1,...,a_N\\}}$$\n",
    "\n",
    "Let us provide several remarks:\n",
    "+ We divide by $\\min(N,10)$ in order to have a perfect score $1$ when the customer buys less than $10$ products and all these products are predicted.\n",
    "+ This definition implicitly assumes that all $y_1,...,y_{10}$ are distinct. If some values are identical, the result can be distorted: for example, if the same product is entered $10$ times and this product is purchased, then the score is $1$. In order to avoid such a case, we ask you to have $10$ different products in your prediction. \n",
    "+ For the private and public score on kaggle, the rank is not taken into account. Nevertheless, we may use the score   **hitrate@K** for $K<10$ after the competition to decide between possible very close groups. So we ask you to give for each product a rank between $1$ and $10$ (i.e. a permutation of $\\{1,...,10\\}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T12:37:50.798252Z",
     "iopub.status.busy": "2024-09-16T12:37:50.797832Z",
     "iopub.status.idle": "2024-09-16T12:37:50.809542Z",
     "shell.execute_reply": "2024-09-16T12:37:50.808173Z",
     "shell.execute_reply.started": "2024-09-16T12:37:50.798211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hitrate@10 evaluation function\n",
    "\n",
    "def hitrate_at_k(true_data: pd.DataFrame,\n",
    "                 predicted_data: pd.DataFrame,\n",
    "                 k: int = 10) -> float:\n",
    "    \"\"\"\n",
    "    This function calculates the hitrate at k for the recommendations.\n",
    "    It assesses how relevant our 10 product recommendations are.\n",
    "    In other words, it calculates the proportion of recommended products that are actually purchased by the customer.\n",
    "\n",
    "    Args:\n",
    "        true_data: a pandas DataFrame containing the true data\n",
    "            customer_id: the customer identifier\n",
    "            product_id: the product identifier that was purchased in the test set\n",
    "        predicted_data: a pandas DataFrame containing the predicted data\n",
    "            customer_id: the customer identifier\n",
    "            product_id: the product identifier that was recommended\n",
    "            rank: the rank of the recommendation. the rank should be between 1 and 10.\n",
    "        k: the number of recommendations to consider. k should be between 1 and 10.\n",
    "    \n",
    "    Returns:\n",
    "        The hitrate at k\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.merge(left = true_data, right = predicted_data, how = \"left\", on = [\"customer_id\", \"product_id\"])\n",
    "    df = data[data[\"rank\"] <= k]\n",
    "    non_null_counts = df.groupby('customer_id')['rank'].apply(lambda x: x.notna().sum()).reset_index(name='non_null_count')\n",
    "    distinct_products_per_customer = data.groupby('customer_id')['product_id'].nunique().reset_index(name='distinct_product_count')\n",
    "    df = pd.merge(left = distinct_products_per_customer, right = non_null_counts, how = \"left\", on = \"customer_id\")\n",
    "    df[\"denominator\"] = [min(df.iloc[i].distinct_product_count,k) for i in range(len(df))]\n",
    "    df = df.fillna(0)\n",
    "    return (df[\"non_null_count\"]/df[\"denominator\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T12:37:50.811481Z",
     "iopub.status.busy": "2024-09-16T12:37:50.811062Z",
     "iopub.status.idle": "2024-09-16T12:38:09.197268Z",
     "shell.execute_reply": "2024-09-16T12:38:09.196094Z",
     "shell.execute_reply.started": "2024-09-16T12:37:50.811439Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the hitrate at k for k = 10\n",
    "frequency_model_hitrate_at_10 = hitrate_at_k(test_data,top_10_recommendations,10)\n",
    "print(f\"Hitrate@10 for the frequency model is {frequency_model_hitrate_at_10:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission file \n",
    "\n",
    "The goal of this part is to provide a function that allows you to encode your prediction in a format that is readable by kaggle when you submit it. In particular, this function checks that you have 10 distinct products per customer and that the ranks are some distinct integers between 1 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T12:38:09.198983Z",
     "iopub.status.busy": "2024-09-16T12:38:09.198626Z",
     "iopub.status.idle": "2024-09-16T12:38:09.313258Z",
     "shell.execute_reply": "2024-09-16T12:38:09.312067Z",
     "shell.execute_reply.started": "2024-09-16T12:38:09.198944Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create submission file for \n",
    "\n",
    "# Keep only the top 10 recommendations for Households between 80001 and 100000\n",
    "prediction = top_10_recommendations[\n",
    "    top_10_recommendations.customer_id.isin(\n",
    "            [\n",
    "                f\"Household_{i}\" for i in range(80001,100001)\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "# Print the solution\n",
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T12:41:26.376277Z",
     "iopub.status.busy": "2024-09-16T12:41:26.374420Z",
     "iopub.status.idle": "2024-09-16T12:41:29.308150Z",
     "shell.execute_reply": "2024-09-16T12:41:29.307064Z",
     "shell.execute_reply.started": "2024-09-16T12:41:26.376219Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_and_format_prediction(df):\n",
    "\n",
    "    # Replace invalid characters in column names\n",
    "    df.columns = df.columns.str.replace('+AF8-', '_', regex=False)\n",
    "    df = df.replace(r'\\+AF8-', '_', regex=True)\n",
    "\n",
    "    # Clean the 'customer_id', 'product_id', and 'transaction_id' columns\n",
    "    if 'customer_id' in df.columns and df['customer_id'].dtype == 'object':\n",
    "        df['customer_id'] = df['customer_id'].str.extract('(\\d+)').fillna(11).astype(int)\n",
    "\n",
    "    if 'product_id' in df.columns and df['product_id'].dtype == 'object':\n",
    "        df['product_id'] = df['product_id'].str.extract('(\\d+)').fillna(11).astype(int)\n",
    "\n",
    "    if 'transaction_id' in df.columns and df['transaction_id'].dtype == 'object':\n",
    "        df['transaction_id'] = df['transaction_id'].str.replace(r'\\D', '', regex=True).fillna(11).astype(int)\n",
    "\n",
    "    df['id'] = df.index\n",
    "    df = df[['id'] + [col for col in df.columns if col != 'id']]\n",
    "\n",
    "    if 'customer_id' not in df.columns or 'product_id' not in df.columns:\n",
    "        raise ValueError(\"true_data must contain 'customer_id' and 'product_id' columns\")\n",
    "\n",
    "    # Group by customer_id and concatenate product and rank values\n",
    "    prediction_grouped = df.groupby('customer_id').agg({\n",
    "        'id': 'first',  # Take the first value of 'id'\n",
    "        'product_id': lambda x: ','.join(map(str, x)),  # Concatenate product_ids into a string\n",
    "        'rank': lambda x: ','.join(map(str, x))  # Concatenate ranks into a string\n",
    "    }).reset_index()\n",
    "\n",
    "    # Drop the 'id' column if it exists\n",
    "    if 'id' in prediction_grouped.columns:\n",
    "        prediction_grouped = prediction_grouped.drop(columns=['id'])\n",
    "\n",
    "    # Filter the data\n",
    "    prediction_grouped = prediction_grouped[prediction_grouped['customer_id'] != 11]\n",
    "    prediction_grouped.insert(0, 'id', range(len(prediction_grouped)))\n",
    "    \n",
    "    # Verify ranks and duplicates\n",
    "    for index, row in prediction_grouped.iterrows():\n",
    "\n",
    "        # Check ranks\n",
    "        ranks = list(map(int, row['rank'].split(',')))\n",
    "\n",
    "        if sorted(ranks) != list(range(1, 11)):  # Check that ranks are distinct from 1 to 10\n",
    "            print(\"Duplicate detected. Ranks must be distinct (from 1 to 10) for each of the 10 predicted products for a customer.\\n\")\n",
    "            return None\n",
    "        \n",
    "        # Check for product duplicates\n",
    "        products = row['product_id'].split(',')\n",
    "        \n",
    "        if len(products) != len(set(products)):  # If duplicates are present in the products\n",
    "            print(\"Duplicate detected. There must be 10 different products per customer.\\n\")\n",
    "            return None\n",
    "\n",
    "    return prediction_grouped\n",
    "\n",
    "prediction_grouped = process_and_format_prediction(prediction)\n",
    "print(prediction_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-16T12:38:09.328593Z",
     "iopub.status.idle": "2024-09-16T12:38:09.329173Z",
     "shell.execute_reply": "2024-09-16T12:38:09.328893Z",
     "shell.execute_reply.started": "2024-09-16T12:38:09.328867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a .csv file to submit on kaggle\n",
    "prediction_grouped.to_csv('submission/submission_list.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9573341,
     "sourceId": 83173,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
